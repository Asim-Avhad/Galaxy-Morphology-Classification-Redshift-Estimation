{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, WeightedRandomSampler\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        # Store all labels for sampling weights calculation\n",
    "        self.labels = []\n",
    "        for img_name in self.image_files:\n",
    "            label_str = img_name.split('_')[-1].split('.')[0]\n",
    "            self.labels.append(int(label_str))\n",
    "        \n",
    "        # Calculate class weights\n",
    "        label_counter = Counter(self.labels)\n",
    "        self.class_weights = {cls: 1.0/count for cls, count in label_counter.items()}\n",
    "        \n",
    "        # Store sample weights for WeightedRandomSampler\n",
    "        self.sample_weights = [self.class_weights[label] for label in self.labels]\n",
    "        self.sample_weights = torch.FloatTensor(self.sample_weights)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = image.resize((128, 128))\n",
    "        \n",
    "        # Data augmentation for training\n",
    "        if torch.rand(1) > 0.5:  # Random horizontal flip\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        # Convert to numpy array and normalize\n",
    "        image_array = np.array(image) / 255.0\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image_tensor = torch.FloatTensor(image_array).permute(2, 0, 1)\n",
    "        \n",
    "        return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "data_dir = os.path.expanduser(\"~/Desktop/BE Project/Decals_data_images\")\n",
    "\n",
    "# Create dataset\n",
    "dataset = GalaxyDataset(root_dir=data_dir)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GalaxyCNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512 * 8 * 8, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss  # for loss, we want to minimize\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score - self.delta:  # Score decreased (got worse)\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:  # Score improved\n",
    "            self.best_score = score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, early_stopping, num_epochs):\n",
    "    model.train()\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': running_loss/len(train_loader),\n",
    "                'accuracy': 100.*correct/total\n",
    "            })\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100. * val_correct / val_total\n",
    "        \n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step(val_accuracy)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc='Evaluating'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 444/444 [01:23<00:00,  5.31it/s, loss=2.49, accuracy=21.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30:\n",
      "Validation Loss: 1.9806\n",
      "Validation Accuracy: 30.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 444/444 [01:33<00:00,  4.75it/s, loss=1.95, accuracy=27.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/30:\n",
      "Validation Loss: 1.8633\n",
      "Validation Accuracy: 30.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 444/444 [01:20<00:00,  5.51it/s, loss=1.8, accuracy=31.8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/30:\n",
      "Validation Loss: 1.6255\n",
      "Validation Accuracy: 36.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 444/444 [01:20<00:00,  5.54it/s, loss=1.68, accuracy=36.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/30:\n",
      "Validation Loss: 1.5622\n",
      "Validation Accuracy: 42.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 444/444 [01:20<00:00,  5.54it/s, loss=1.64, accuracy=38]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/30:\n",
      "Validation Loss: 1.5864\n",
      "Validation Accuracy: 39.32%\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 444/444 [01:20<00:00,  5.54it/s, loss=1.56, accuracy=40.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/30:\n",
      "Validation Loss: 1.5620\n",
      "Validation Accuracy: 44.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 444/444 [01:19<00:00,  5.56it/s, loss=1.49, accuracy=42.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/30:\n",
      "Validation Loss: 1.4143\n",
      "Validation Accuracy: 46.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 444/444 [01:19<00:00,  5.57it/s, loss=1.48, accuracy=43.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/30:\n",
      "Validation Loss: 1.4078\n",
      "Validation Accuracy: 49.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 444/444 [01:19<00:00,  5.56it/s, loss=1.4, accuracy=46.7]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/30:\n",
      "Validation Loss: 1.5264\n",
      "Validation Accuracy: 42.70%\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 444/444 [01:19<00:00,  5.56it/s, loss=1.38, accuracy=47.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/30:\n",
      "Validation Loss: 1.3496\n",
      "Validation Accuracy: 54.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 444/444 [01:19<00:00,  5.56it/s, loss=1.34, accuracy=49.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/30:\n",
      "Validation Loss: 1.2709\n",
      "Validation Accuracy: 50.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 444/444 [01:19<00:00,  5.56it/s, loss=1.28, accuracy=51.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/30:\n",
      "Validation Loss: 1.2648\n",
      "Validation Accuracy: 57.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 444/444 [01:19<00:00,  5.58it/s, loss=1.24, accuracy=53.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/30:\n",
      "Validation Loss: 1.3396\n",
      "Validation Accuracy: 53.64%\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 444/444 [01:19<00:00,  5.57it/s, loss=1.18, accuracy=55.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/30:\n",
      "Validation Loss: 1.3484\n",
      "Validation Accuracy: 47.24%\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 444/444 [01:19<00:00,  5.57it/s, loss=1.15, accuracy=57.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/30:\n",
      "Validation Loss: 1.3497\n",
      "Validation Accuracy: 53.66%\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 444/444 [01:19<00:00,  5.57it/s, loss=1.12, accuracy=58.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/30:\n",
      "Validation Loss: 1.1450\n",
      "Validation Accuracy: 62.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 444/444 [01:19<00:00,  5.58it/s, loss=1.06, accuracy=60.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/30:\n",
      "Validation Loss: 1.0811\n",
      "Validation Accuracy: 65.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 444/444 [01:19<00:00,  5.58it/s, loss=1.03, accuracy=62.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/30:\n",
      "Validation Loss: 1.0324\n",
      "Validation Accuracy: 65.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 444/444 [01:19<00:00,  5.58it/s, loss=0.979, accuracy=64.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/30:\n",
      "Validation Loss: 0.9793\n",
      "Validation Accuracy: 66.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 444/444 [01:19<00:00,  5.57it/s, loss=0.961, accuracy=65]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/30:\n",
      "Validation Loss: 1.0227\n",
      "Validation Accuracy: 64.40%\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 444/444 [01:20<00:00,  5.50it/s, loss=0.899, accuracy=67.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/30:\n",
      "Validation Loss: 0.9451\n",
      "Validation Accuracy: 68.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 444/444 [01:19<00:00,  5.55it/s, loss=0.888, accuracy=67.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/30:\n",
      "Validation Loss: 1.5426\n",
      "Validation Accuracy: 48.99%\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 444/444 [01:20<00:00,  5.55it/s, loss=0.861, accuracy=69.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/30:\n",
      "Validation Loss: 0.9562\n",
      "Validation Accuracy: 69.45%\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 444/444 [01:19<00:00,  5.56it/s, loss=0.84, accuracy=70.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/30:\n",
      "Validation Loss: 1.0230\n",
      "Validation Accuracy: 67.98%\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 444/444 [01:19<00:00,  5.57it/s, loss=0.803, accuracy=71]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/30:\n",
      "Validation Loss: 1.1273\n",
      "Validation Accuracy: 64.09%\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 444/444 [01:19<00:00,  5.56it/s, loss=0.777, accuracy=71.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/30:\n",
      "Validation Loss: 1.0327\n",
      "Validation Accuracy: 64.32%\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 111/111 [00:13<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.81%\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders with weighted sampling for training\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    sampler=WeightedRandomSampler(\n",
    "        weights=dataset.sample_weights[:train_size],\n",
    "        num_samples=train_size,\n",
    "        replacement=True\n",
    "    )\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model and move to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GalaxyCNN(num_classes=10).to(device)\n",
    "\n",
    "# Setup class weights for loss function\n",
    "class_weights = torch.FloatTensor([\n",
    "    1.0/1081,  # Class 0\n",
    "    1.0/1853,  # Class 1\n",
    "    1.0/2645,  # Class 2\n",
    "    1.0/2027,  # Class 3\n",
    "    1.0/334,   # Class 4\n",
    "    1.0/2043,  # Class 5\n",
    "    1.0/1829,  # Class 6\n",
    "    1.0/2628,  # Class 7\n",
    "    1.0/1423,  # Class 8\n",
    "    1.0/1873   # Class 9\n",
    "]).to(device)\n",
    "\n",
    "# Initialize criterion, optimizer, scheduler, and early stopping\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=5,  # Reduced patience\n",
    "    verbose=True,\n",
    "    delta=0.01  # Minimum change to qualify as an improvement\n",
    ")\n",
    "# Modify scheduler parameters\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',\n",
    "    factor=0.1, \n",
    "    patience=3,  # Reduced patience\n",
    "    verbose=True,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Train model\n",
    "num_epochs = 30\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, early_stopping, num_epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"galaxy_cnn_balanced.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
