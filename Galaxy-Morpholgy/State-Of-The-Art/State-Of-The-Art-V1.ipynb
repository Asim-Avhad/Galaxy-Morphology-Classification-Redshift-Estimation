{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 1.4385, Accuracy: 42.54%\n",
      "Epoch 2/30, Loss: 1.2111, Accuracy: 51.11%\n",
      "Epoch 3/30, Loss: 1.1365, Accuracy: 53.71%\n",
      "Epoch 4/30, Loss: 1.0897, Accuracy: 55.34%\n",
      "Epoch 5/30, Loss: 1.0422, Accuracy: 57.28%\n",
      "Epoch 6/30, Loss: 0.9975, Accuracy: 59.53%\n",
      "Epoch 7/30, Loss: 0.9779, Accuracy: 60.67%\n",
      "Epoch 8/30, Loss: 0.9399, Accuracy: 62.35%\n",
      "Epoch 9/30, Loss: 0.9123, Accuracy: 63.89%\n",
      "Epoch 10/30, Loss: 0.8764, Accuracy: 65.34%\n",
      "Epoch 11/30, Loss: 0.8459, Accuracy: 67.17%\n",
      "Epoch 12/30, Loss: 0.8058, Accuracy: 69.46%\n",
      "Epoch 13/30, Loss: 0.7778, Accuracy: 70.51%\n",
      "Epoch 14/30, Loss: 0.7380, Accuracy: 72.76%\n",
      "Epoch 15/30, Loss: 0.7153, Accuracy: 73.24%\n",
      "Epoch 16/30, Loss: 0.6848, Accuracy: 74.62%\n",
      "Epoch 17/30, Loss: 0.6603, Accuracy: 75.80%\n",
      "Epoch 18/30, Loss: 0.6356, Accuracy: 76.76%\n",
      "Epoch 19/30, Loss: 0.6138, Accuracy: 77.35%\n",
      "Epoch 20/30, Loss: 0.5991, Accuracy: 77.86%\n",
      "Epoch 21/30, Loss: 0.5796, Accuracy: 78.74%\n",
      "Epoch 22/30, Loss: 0.5734, Accuracy: 79.10%\n",
      "Epoch 23/30, Loss: 0.5520, Accuracy: 80.03%\n",
      "Epoch 24/30, Loss: 0.5379, Accuracy: 80.29%\n",
      "Epoch 25/30, Loss: 0.5311, Accuracy: 80.66%\n",
      "Epoch 26/30, Loss: 0.5214, Accuracy: 81.04%\n",
      "Epoch 27/30, Loss: 0.5122, Accuracy: 81.36%\n",
      "Epoch 28/30, Loss: 0.4990, Accuracy: 81.92%\n",
      "Epoch 29/30, Loss: 0.4991, Accuracy: 81.95%\n",
      "Epoch 30/30, Loss: 0.4826, Accuracy: 82.35%\n",
      "Training complete!\n",
      "Test Accuracy: 76.06%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom Dataset for Galaxy10\n",
    "def load_galaxy10_data():\n",
    "    with h5py.File(\"Galaxy10.h5\", \"r\") as f:\n",
    "        images = np.array(f[\"images\"])  # Shape: (N, H, W, C)\n",
    "        labels = np.array(f[\"ans\"])  # Shape: (N,)\n",
    "    return images, labels\n",
    "\n",
    "class Galaxy10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to PIL Image (Ensure 3 channels)\n",
    "        image = Image.fromarray(image[:, :, :3])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "images, labels = load_galaxy10_data()\n",
    "dataset = Galaxy10Dataset(images, labels, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define CvT Model\n",
    "class CvT(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CvT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(256 * 28 * 28, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize Model, Loss, Optimizer\n",
    "model = CvT().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Testing Loop\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
