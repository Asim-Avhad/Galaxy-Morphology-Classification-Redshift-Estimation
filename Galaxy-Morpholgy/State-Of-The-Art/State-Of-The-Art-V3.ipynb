{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5df978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aseem\\AppData\\Local\\Temp\\ipykernel_19236\\2456794716.py:286: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 1178170 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/1090 [00:00<?, ?it/s]C:\\Users\\Aseem\\AppData\\Local\\Temp\\ipykernel_19236\\2456794716.py:318: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/50: 100%|██████████| 1090/1090 [02:36<00:00,  6.95it/s, accuracy=30.7, loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.8238, Accuracy: 30.67%\n",
      "Model saved at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 1090/1090 [02:23<00:00,  7.57it/s, accuracy=31.7, loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 1.7475, Accuracy: 31.69%\n",
      "Model saved at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 1090/1090 [02:25<00:00,  7.48it/s, accuracy=31.3, loss=1.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 1.7481, Accuracy: 31.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 1090/1090 [02:27<00:00,  7.40it/s, accuracy=31.7, loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 1.7471, Accuracy: 31.71%\n",
      "Model saved at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 1090/1090 [02:21<00:00,  7.70it/s, accuracy=31.7, loss=1.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 1.7469, Accuracy: 31.72%\n",
      "Model saved at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 1090/1090 [03:12<00:00,  5.67it/s, accuracy=31.6, loss=2.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 1.7476, Accuracy: 31.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 1090/1090 [02:36<00:00,  6.95it/s, accuracy=31.9, loss=1.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 1.7473, Accuracy: 31.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 1090/1090 [02:19<00:00,  7.83it/s, accuracy=31.9, loss=1.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 1.7473, Accuracy: 31.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 1090/1090 [02:22<00:00,  7.64it/s, accuracy=31.7, loss=1.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 1.7475, Accuracy: 31.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 1090/1090 [02:23<00:00,  7.61it/s, accuracy=31.7, loss=1.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 1.7470, Accuracy: 31.68%\n",
      "Early stopping triggered.\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/273 [00:00<?, ?it/s]C:\\Users\\Aseem\\AppData\\Local\\Temp\\ipykernel_19236\\2456794716.py:387: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Testing: 100%|██████████| 273/273 [00:03<00:00, 78.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 32.22%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       692\n",
      "           1      0.322     1.000     0.487      1404\n",
      "           2      0.000     0.000     0.000      1251\n",
      "           3      0.000     0.000     0.000        76\n",
      "           4      0.000     0.000     0.000       316\n",
      "           5      0.000     0.000     0.000         5\n",
      "           6      0.000     0.000     0.000       125\n",
      "           7      0.000     0.000     0.000       218\n",
      "           8      0.000     0.000     0.000       172\n",
      "           9      0.000     0.000     0.000        98\n",
      "\n",
      "    accuracy                          0.322      4357\n",
      "   macro avg      0.032     0.100     0.049      4357\n",
      "weighted avg      0.104     0.322     0.157      4357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Aseem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aseem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Aseem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Check if CUDA is available and set memory management\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set up CUDA memory management\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    # Enable memory optimization\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Custom Dataset for Galaxy10\n",
    "def load_galaxy10_data():\n",
    "    with h5py.File(\"Galaxy10.h5\", \"r\") as f:\n",
    "        images = np.array(f[\"images\"])  # Shape: (N, H, W, C)\n",
    "        labels = np.array(f[\"ans\"])  # Shape: (N,)\n",
    "    return images, labels\n",
    "\n",
    "class Galaxy10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to PIL Image (Ensure 3 channels)\n",
    "        image = Image.fromarray(image[:, :, :3])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define Transformations - Further reduce image size to save memory\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),  # Reduced from 112x112 to 96x96\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load Dataset - with memory optimization\n",
    "def get_dataloaders():\n",
    "    images, labels = load_galaxy10_data()\n",
    "    dataset = Galaxy10Dataset(images, labels, transform=transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Further reduce batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True)  # Reduced to 16\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, pin_memory=True)  # Reduced to 16\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Convolutional Token Embedding with reduced parameters\n",
    "class ConvTokenEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(ConvTokenEmbedding, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                             stride=stride, padding=padding)\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "        self.activation = nn.GELU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)  # [B, C, H, W]\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.permute(0, 2, 3, 1)  # [B, H, W, C]\n",
    "        x = self.norm(x)  # LayerNorm over channel dimension\n",
    "        x = self.activation(x)\n",
    "        x = x.permute(0, 3, 1, 2)  # [B, C, H, W]\n",
    "        return x\n",
    "\n",
    "# Memory-efficient Convolutional Projection\n",
    "class ConvolutionalProjection(nn.Module):\n",
    "    def __init__(self, dim, kernel_size=3, stride=1, padding=1):\n",
    "        super(ConvolutionalProjection, self).__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, kernel_size=kernel_size, stride=stride, padding=padding, groups=dim)\n",
    "        \n",
    "    def forward(self, x, H, W):\n",
    "        B, N, C = x.shape\n",
    "        x = x.transpose(1, 2).view(B, C, H, W)\n",
    "        x = self.conv(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "# Simplified Attention with lower memory footprint\n",
    "class ConvAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
    "        super(ConvAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        assert dim % num_heads == 0, f\"dim {dim} should be divisible by num_heads {num_heads}\"\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        # Use separate projections to save memory during backward pass\n",
    "        self.q = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.k = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        self.v = nn.Linear(dim, dim, bias=qkv_bias)\n",
    "        \n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        B, N, C = x.shape\n",
    "        \n",
    "        # Project q, k, v separately to save memory\n",
    "        q = self.q(x).reshape(B, N, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        k = self.k(x).reshape(B, N, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        v = self.v(x).reshape(B, N, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        # Attention computation with memory efficiency\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        \n",
    "        # Clean up intermediate tensors\n",
    "        del q, k, v, attn\n",
    "        return x\n",
    "\n",
    "# Reduced MLP Block\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.):\n",
    "        super(MLP, self).__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        # Further reduce hidden features\n",
    "        hidden_features = int(hidden_features * 0.5)  # 50% reduction in hidden dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "# Optimized Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = ConvAttention(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = MLP(in_features=dim, hidden_features=int(dim * mlp_ratio * 0.5), drop=drop)  # 50% reduction\n",
    "        \n",
    "    def forward(self, x, H, W):\n",
    "        # Use clone to save memory in backward pass\n",
    "        x_norm = self.norm1(x)\n",
    "        x = x + self.attn(x_norm, H, W)\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "# Simplified CvT Stage\n",
    "class CvTStage(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, depth, num_heads, mlp_ratio=4.):\n",
    "        super(CvTStage, self).__init__()\n",
    "        self.embedding = ConvTokenEmbedding(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(out_channels, num_heads, mlp_ratio=mlp_ratio)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # [B, C, H, W]\n",
    "        H, W = x.shape[2], x.shape[3]\n",
    "        x = x.flatten(2).permute(0, 2, 1)  # [B, H*W, C]\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x, H, W)\n",
    "            \n",
    "        return x, H, W\n",
    "\n",
    "# Much reduced CvT Model\n",
    "class CvT(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_channels=3):\n",
    "        super(CvT, self).__init__()\n",
    "        # Stage 1 parameters - reduced dimensions\n",
    "        s1_embed_dim = 48  # Reduced from 64\n",
    "        s1_kernel_size = 7\n",
    "        s1_stride = 4\n",
    "        s1_padding = 3\n",
    "        s1_depth = 1\n",
    "        s1_num_heads = 1\n",
    "        \n",
    "        # Stage 2 parameters - reduced dimensions\n",
    "        s2_embed_dim = 96  # Reduced from 192\n",
    "        s2_kernel_size = 3\n",
    "        s2_stride = 2\n",
    "        s2_padding = 1\n",
    "        s2_depth = 1  # Reduced to 1\n",
    "        s2_num_heads = 3\n",
    "        \n",
    "        # Stage 3 parameters - reduced dimensions\n",
    "        s3_embed_dim = 192  # Reduced from 384\n",
    "        s3_kernel_size = 3\n",
    "        s3_stride = 2\n",
    "        s3_padding = 1\n",
    "        s3_depth = 4  # Reduced from 6 to 4\n",
    "        s3_num_heads = 6\n",
    "        \n",
    "        # Define stages\n",
    "        self.stage1 = CvTStage(in_channels, s1_embed_dim, s1_kernel_size, s1_stride, s1_padding, s1_depth, s1_num_heads)\n",
    "        self.stage2 = CvTStage(s1_embed_dim, s2_embed_dim, s2_kernel_size, s2_stride, s2_padding, s2_depth, s2_num_heads)\n",
    "        self.stage3 = CvTStage(s2_embed_dim, s3_embed_dim, s3_kernel_size, s3_stride, s3_padding, s3_depth, s3_num_heads)\n",
    "        \n",
    "        # Classification head\n",
    "        self.norm = nn.LayerNorm(s3_embed_dim)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, s3_embed_dim))\n",
    "        self.head = nn.Linear(s3_embed_dim, num_classes)\n",
    "        \n",
    "        # Initialize cls token\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        \n",
    "        # Process through stages\n",
    "        x, H1, W1 = self.stage1(x)\n",
    "        x = x.permute(0, 2, 1).reshape(B, 48, H1, W1)  # [B, C, H, W]\n",
    "        \n",
    "        x, H2, W2 = self.stage2(x)\n",
    "        x = x.permute(0, 2, 1).reshape(B, 96, H2, W2)  # [B, C, H, W]\n",
    "        \n",
    "        x, H3, W3 = self.stage3(x)  # [B, H*W, C]\n",
    "        \n",
    "        # Add classification token\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        \n",
    "        # Apply layer norm\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # Use only the cls token for classification\n",
    "        x = x[:, 0]\n",
    "        \n",
    "        # Classification head\n",
    "        x = self.head(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def train_and_evaluate():\n",
    "    # Get dataloaders\n",
    "    train_loader, test_loader = get_dataloaders()\n",
    "    \n",
    "    # Increase gradient accumulation steps\n",
    "    accumulation_steps = 4  # Increased from 2 to 4\n",
    "    \n",
    "    # Initialize Model, Loss, Optimizer\n",
    "    model = CvT().to(device)\n",
    "    \n",
    "    # Enable mixed precision training if available\n",
    "    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    \n",
    "    # Print model summary\n",
    "    print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "    \n",
    "    # Training Loop with Early Stopping and gradient accumulation\n",
    "    num_epochs = 50\n",
    "    early_stopping_patience = 5\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Empty cache before each epoch\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        optimizer.zero_grad()  # Zero gradients at the beginning of each epoch\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Use mixed precision training if available\n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels) / accumulation_steps\n",
    "                \n",
    "                # Scale gradients and call backward\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # Update weights every accumulation_steps batches\n",
    "                if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "            else:\n",
    "                # Regular training for CPU\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels) / accumulation_steps\n",
    "                loss.backward()\n",
    "                \n",
    "                if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "            running_loss += loss.item() * accumulation_steps\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            progress_bar.set_postfix(loss=loss.item() * accumulation_steps, accuracy=100 * correct / total)\n",
    "            \n",
    "            # Clear memory for this batch\n",
    "            del images, labels, outputs, loss\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            gc.collect()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        # Early Stopping Check\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            # Save model checkpoint\n",
    "            torch.save(model.state_dict(), 'best_cvt_model.pth')\n",
    "            print(f\"Model saved at epoch {epoch+1}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    # Load best model for testing\n",
    "    model.load_state_dict(torch.load('best_cvt_model.pth'))\n",
    "    \n",
    "    # Testing Loop\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Use mixed precision for evaluation as well\n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(images)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # Clear memory for this batch\n",
    "            del images, labels, outputs, probs\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, digits=3))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
